{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉熵(Cross_entropy)是Loss函数的一种，用于描述预测值与真实值的差距大小，常见的Loss函数是均方平方误差(Mean Squared Erros,MSE),定义如下:\n",
    "\n",
    "$$Error = \\frac{(y - \\bar{y})^{2}}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow交叉熵函数的输入logits未经过softmax或sigmoid函数处理，TensorFlow交叉熵函数会在其内部进行softmax或sigmoid函数的处理。TensorFlow针对分类问题，实现了五个交叉熵函数，分别是：\n",
    "1. [tf.nn.sigmoid_cross_entropy_with_logits](https://tensorflow.google.cn/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits)\n",
    "2. [tf.nn.softmax_cross_entropy_with_logits](https://tensorflow.google.cn/api_docs/python/tf/nn/softmax_cross_entropy_with_logits)\n",
    "3. [tf.nn.sparse_softmax_cross_entropy_with_logits](https://tensorflow.google.cn/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits)\n",
    "4. [tf.nn.weighted_cross_entropy_with_logits](https://tensorflow.google.cn/api_docs/python/tf/nn/weighted_cross_entropy_with_logits)\n",
    "5. [tf.nn.softmax_cross_entropy_with_logits_v2](https://tensorflow.google.cn/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.sigmoid_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=labels),logits的维度和labels的维度是一致的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对输入的logits，先通过sigmoid函数将logits各个维度的值压缩到\\[0,1\\]之间，再计算它们的交叉熵，过程如下：\n",
    "1. 类别标签\n",
    "$$y = labels$$\n",
    "例如 有三个样本，其类别标签便如下所示：\n",
    "$$y = [[1,0,0],[0,1,0],[0,0,1]]$$\n",
    "\n",
    "2. sigmoid处理logits\n",
    "$$p_{ij} = sigmoid(logits_{ij}) = \\frac{1}{1 + e^{-logits_{ij}}}$$\n",
    "由于logits与labels的维度是一致的，并且此处$p_{ij}$是指$logits[i]$第$j$个维度的值，因此假设\n",
    "$$logits = [[56,32,24],[88,55,74],[66,12,34]]$$\n",
    "经过sigmoid函数处理后的值为\n",
    "$$sigmoid(logits) = [[1,1,1],[1,1,1],[1,0.99,1]]$$\n",
    "\n",
    "3. 计算交叉熵损失\n",
    "$$loss_{ij} = -[y_{ij}*lnp_{ij} + (1 - y_{ij})*ln(1 - p_{ij})]$$\n",
    "这里$y_{ij}$是$y[i]$第$j$个维度的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 适用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个类别相互独立但互不排斥的情况，例如一幅图中可以同时包含一条狗和一只大象，具体看例子中第4个样本，同时属于两个类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output不是一个数，而是一个batch中每个样本的loss，因此一般配合`tf.reduce_mean(loss)`使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T09:39:48.102037Z",
     "start_time": "2019-04-17T09:39:47.952923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred:  [[0.99999386 0.95257413 0.88079708]\n",
      " [0.95257413 0.9999546  0.73105858]\n",
      " [0.73105858 0.88079708 0.99330715]\n",
      " [0.98201379 0.99849882 0.76852478]\n",
      " [0.95257413 0.99752738 0.73105858]]\n",
      "E1:  [[6.14419348e-06 3.04858735e+00 2.12692801e+00]\n",
      " [3.04858735e+00 4.53988992e-05 1.31326169e+00]\n",
      " [1.31326169e+00 2.12692801e+00 6.71534849e-03]\n",
      " [1.81499279e-02 1.50231016e-03 1.46328247e+00]\n",
      " [3.04858735e+00 2.47568514e-03 1.31326169e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "'定义sigmoid函数'\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "# 5个样本三分类问题\n",
    "y = np.array([[1,0,0],[0,1,0],[0,0,1],[1,1,0],[0,1,0]]) # 注意第4个样本同时属于两个类\n",
    "logits = np.array([[12,3,2],[3,10,1],[1,2,5],[4,6.5,1.2],[3,6,1]])\n",
    "# sigmoid函数处理logits\n",
    "y_pred = sigmoid(logits)\n",
    "# 计算交叉熵\n",
    "E1 = -y * np.log(y_pred) - (1 - y) * np.log(1 - y_pred)\n",
    "print('y_pred: ',y_pred)\n",
    "print('E1: ',E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T09:39:50.250125Z",
     "start_time": "2019-04-17T09:39:48.105029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E2:  [[6.14419348e-06 3.04858735e+00 2.12692801e+00]\n",
      " [3.04858735e+00 4.53988992e-05 1.31326169e+00]\n",
      " [1.31326169e+00 2.12692801e+00 6.71534849e-03]\n",
      " [1.81499279e-02 1.50231016e-03 1.46328247e+00]\n",
      " [3.04858735e+00 2.47568514e-03 1.31326169e+00]]\n",
      "loss:  1.255438694766465\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'TensorFlow版本的计算'\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "y = np.array(y).astype(np.float64) # labels是float64的数据类型\n",
    "E2 = sess.run(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "print('E2: ',E2)\n",
    "loss = tf.reduce_mean(E2)\n",
    "loss = sess.run(loss)\n",
    "print('loss: ',loss)\n",
    "\n",
    "'比较E1与E2的结果'\n",
    "if E1.all() == E2.all():\n",
    "    print('True')\n",
    "else:\n",
    "    print('False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由此可知计算出的交叉熵值，是logits每个维度对应的交叉熵损失。需要通过`tf.reduce_mean(loss)`来将所有交叉熵损失加总，此时不指定axis的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.softmax_cross_entropy_with_logits(\\_sentinel=None,labels=None,logits=None,dim=-1,name=None)\n",
    "\n",
    "**labels**：和logits具有相同的type和shape的张量，是一个有效的概率。它满足`sum(labels)=1,one_hot=True`,即向量中只有一个值为1.0，其他值为0.0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对输入的logits，先通过softmax函数将logits各个维度的值压缩到\\[0,1\\]之间，此时logits各个维度的值的和为1，再计算它们的交叉熵，过程如下：\n",
    "\n",
    "1. 类别标签\n",
    "$$y = labels$$\n",
    "例如 有三个样本，其类别标签便如下所示：\n",
    "$$y = [[1,0,0],[0,1,0],[0,0,1]]$$\n",
    "\n",
    "2. softmax处理logits\n",
    "$$p_{ij} = softmax(logits_{i}) = \\frac{e^{logits_{ij}}}{\\sum_{j=0}^{numclasses-1} e^{logits_{ij}}}$$\n",
    "由于logits与labels的维度是一致的，并且此处$p_{ij}$是指$logits[i]$第$j$个维度的值，因此假设\n",
    "$$logits = [[56,32,24],[88,55,74],[66,12,34]]$$\n",
    "经过softmax函数处理后的值为\n",
    "$$softmax(logits) = \\begin{bmatrix}1.00000000e+00 & 3.77513454e-11 & 1.26641655e-14 \\\\\n",
    "       9.99999168e-01 & 4.65888227e-15 & 8.31528028e-07 \\\\\n",
    "       1.00000000e+00 & 3.53262857e-24 & 1.26641655e-14\\end{bmatrix}$$\n",
    "\n",
    "3. 计算交叉熵损失\n",
    "$$loss_{i} = -\\sum_{j=0}^{numclasses-1}y_{ij}*lnp_{ij}$$\n",
    "这里$y_{ij}$是$y[i]$第$j$个维度的值,此时loss是一个标量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 适用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个类别相互独立且相互排斥的情况，例如一幅图只能属于一类，而不能同时包含一条狗和一只大象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output不是一个数，而是一个batch中每个样本的loss，因此一般配合`tf.reduce_mean(loss)`使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T09:39:50.263044Z",
     "start_time": "2019-04-17T09:39:50.251076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred :  [[9.99831219e-01 1.23388975e-04 4.53922671e-05]\n",
      " [9.10938878e-04 9.98965779e-01 1.23282171e-04]\n",
      " [1.71478255e-02 4.66126226e-02 9.36239552e-01]\n",
      " [7.55098575e-02 9.19898383e-01 4.59175917e-03]\n",
      " [4.71234165e-02 9.46499123e-01 6.37746092e-03]]\n",
      "E1 :  [1.68795487e-04 1.03475622e-03 6.58839038e-02 2.58349207e+00\n",
      " 5.49852354e-02]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    sum_raw = np.sum(np.exp(x),axis=-1) # 沿着横轴方向累加，注意numpy的axis取值方式与TensorFlow不同\n",
    "    x1 = np.ones(np.shape(x))\n",
    "    for i in range(np.shape(x)[0]):\n",
    "        x1[i] = np.exp(x[i]) / sum_raw[i]\n",
    "    return x1\n",
    "\n",
    "y = np.array([[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0]])# 每一行只有一个1\n",
    "logits =np.array([[12,3,2],[3,10,1],[1,2,5],[4,6.5,1.2],[3,6,1]])\n",
    "# logits经过softmax处理后\n",
    "y_pred = softmax(logits)\n",
    "# 计算交叉熵损失\n",
    "E1 = - np.sum(y * np.log(y_pred),axis=-1)\n",
    "print('y_pred : ',y_pred)\n",
    "print('E1 : ',E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T09:39:50.331862Z",
     "start_time": "2019-04-17T09:39:50.266036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-3dfa6a822724>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "E2 :  [1.68795487e-04 1.03475622e-03 6.58839038e-02 2.58349207e+00\n",
      " 5.49852354e-02]\n",
      "loss :  0.5411129517625908\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'TensorFlow版本'\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "y = np.array(y).astype(np.float64)\n",
    "E2 = sess.run(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits))\n",
    "loss = sess.run(tf.reduce_mean(E2))\n",
    "print('E2 : ',E2)\n",
    "print('loss : ',loss)\n",
    "\n",
    "'比较E1与E2的结果'\n",
    "if E1.all() == E2.all():\n",
    "    print('True')\n",
    "else:\n",
    "    print('False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由此可知计算出的交叉熵值，是每个logits对应的交叉熵损失，由于共有5个样本，所以交叉熵损失有5个值。需要通过`tf.reduce_mean(loss)`来将所有交叉熵损失加总，此时不指定axis的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.sparse_softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.weighted_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.softmax_cross_entropy_with_logits_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
