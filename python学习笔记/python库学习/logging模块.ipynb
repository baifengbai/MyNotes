{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 何为日志"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日志是一种可以追踪某些软件运行时所发生事件的方法。一个事件可以用一个可包含可选变量数据的消息来描述。此外，事件也有重要性的概念，这个重要性被称为严重性级别(level)。\n",
    "\n",
    "一条日志信息对应的是一个事件的发生，而一个事件通常需要包括以下几个内容：\n",
    "1. 事件发生的时间\n",
    "2. 事件发生的位置\n",
    "3. 事件的严重程度：日志级别\n",
    "4. 事件内容\n",
    "\n",
    "上面这些都是一条日志记录LogRecord可能包含的字段信息，当然还可以包括一些其他信息，如进程ID、进程名称、线程ID、线程名称等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日志等级"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先来思考下下面的两个问题：\n",
    "1. 作为开发人员，在开发一个应用程序时需要什么日志信息？在应用程序正式上线后需要什么日志信息？\n",
    "2. 作为应用运维人员，在部署开发环境时需要什么日志信息？在部署生产环境时需要什么日志信息？\n",
    "\n",
    "在软件开发阶段或部署开发环境时，为了尽可能详细地查看应用程序的运行状态来保证上线后的稳定性，我们可能需要把该应用程序所有的运行日志全部记录下来进行分析，这是非常耗费机器性能的。\n",
    "\n",
    "当应用程序正式发布或在生产环境部署应用程序时，我们通常只需要记录应用程序的异常信息、错误信息等，这样既可以减小服务器的I/O压力，也可以避免我们在排查故障时被淹没在日志的海洋里。\n",
    "\n",
    "那么，怎样才能在不改动应用程序代码的情况下实现在不同的环境记录不同详细程度的日志呢？这就是日志等级的作用了，我们通过配置文件指定我们需要的日志等级就可以了。不同的应用程序所定义的日志等级可能会有所差别，分的详细点的会包含以下几个等级：\n",
    "\n",
    "|日志级别|何时使用|数值|\n",
    "|:--:|:--:|:--|\n",
    "|CRITICAL|严重错误，表明软件已不能继续运行了|50|\n",
    "|ERROR|由于更严重的问题，软件已不能执行一些功能了。 一般错误消息|40|\n",
    "|WARNING|表明发生了一些意外，或者不久的将来会发生问题（如‘磁盘满了’）。软件还是在正常工作|30|\n",
    "|INFO|证明事情按预期工作。 关键事件|20|\n",
    "|DEBUG|详细信息，典型地调试问题时会感兴趣。 详细的debug信息|10|\n",
    "|NOTSET|通知信息|0|\n",
    "\n",
    "这里最高的等级是 CRITICAL 和 FATAL，两个对应的数值都是 50，另外对于 WARNING 还提供了简写形式 WARN，两个对应的数值都是 30。\n",
    "\n",
    "如果我们设置了输出日志的 level，系统便只会输出 level 数值**大于或等于**该 level 的的日志结果，例如我们设置了输出日志 level 为 INFO，那么输出级别大于等于 INFO 的日志，如 WARNING、ERROR 等，而 DEBUG 和 NOSET 级别的不会输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日志记录的重要性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过log的分析，可以方便用户了解系统或软件、应用的运行情况；如果你的应用log足够丰富，也可以分析以往用户的操作行为、类型喜好、地域分布或其他更多信息；如果一个应用的log同时也分了多个级别，那么可以很轻易地分析得到该应用的健康状况，及时发现问题并快速定位、解决问题，补救损失。\n",
    "\n",
    "简单来讲就是，我们通过记录和分析日志可以了解一个系统或软件程序运行情况是否正常，也可以在应用程序出现故障时快速定位问题。比如，做运维的同学，在接收到报警或各种问题反馈后，进行问题排查时通常都会先去看各种日志，大部分问题都可以在日志中找到答案。再比如，做开发的同学，可以通过IDE控制台上输出的各种日志进行程序调试。对于运维老司机或者有经验的开发人员，可以快速的通过日志定位到问题的根源。可见，日志的重要性不可小觑。日志的作用可以简单总结为以下3点：\n",
    "1. 程序调试\n",
    "2. 了解软件程序运行情况是否正常\n",
    "3. 软件程序运行故障分析与问题定位\n",
    "\n",
    "在开发过程中，如果程序运行出现了问题，我们是可以使用我们自己的 Debug 工具来检测到到底是哪一步出现了问题，如果出现了问题的话，是很容易排查的。但程序开发完成之后，我们会将它部署到生产环境中去，这时候代码相当于是在一个黑盒环境下运行的，我们只能看到其运行的效果，是不能直接看到代码运行过程中每一步的状态的。在这个环境下，运行过程中难免会在某个地方出现问题，甚至这个问题可能是我们开发过程中未曾遇到的问题，碰到这种情况应该怎么办？\n",
    "\n",
    "如果我们现在只能得知当前问题的现象，而没有其他任何信息的话，如果我们想要解决掉这个问题的话，那么只能根据问题的现象来试图复现一下，然后再一步步去调试，这恐怕是很难的，很大的概率上我们是无法精准地复现这个问题的，而且 Debug 的过程也会耗费巨多的时间，这样一旦生产环境上出现了问题，修复就会变得非常棘手。但这如果我们当时有做日志记录的话，不论是正常运行还是出现报错，都有相关的时间记录，状态记录，错误记录等，那么这样我们就可以方便地追踪到在当时的运行过程中出现了怎样的状况，从而可以快速排查问题。\n",
    "\n",
    "因此，日志记录是非常有必要的，任何一款软件如果没有标准的日志记录，都不能算作一个合格的软件。作为开发者，我们需要重视并做好日志记录过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日志记录的流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么在 Python 中，怎样才能算作一个比较标准的日志记录过程呢？或许很多人会使用 print 语句输出一些运行信息，然后再在控制台观察，运行的时候再将输出重定向到文件输出流保存到文件中，这样其实是非常不规范的，在 Python 中有一个标准的 `logging` 模块，我们可以使用它来进行标准的日志记录，利用它我们可以更方便地进行日志记录，同时还可以做更方便的级别区分以及一些额外日志信息的记录，如时间、运行模块信息等。接下来我们先了解一下日志记录流程的整体框架：\n",
    "\n",
    "![](./image/logging.png)\n",
    "\n",
    "日志流处理的简要流程：\n",
    "1. 创建一个日志器Logger\n",
    "2. 设置Logger的日志等级\n",
    "3. 创建合适的处理器Handler(FileHandler要有路径)\n",
    "4. 设置每个Handler的日志等级\n",
    "5. 用Formatter创建日志记录的格式\n",
    "6. 向Handler中添加上面的日志格式\n",
    "7. 将上面创建的Handler添加到Logger中\n",
    "8. 打印输出logger.debug\\logger.info\\logger.warning\\logger.error\\logger.critical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Logger：日志器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即`Logger Main Class`是我们进行日志记录时创建的对象，我们可以调用它的方法传入日志模板和信息，来生成一条条日志记录，称作`LogRecord`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogRecord：日志记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指生成的一条条日志记录。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handler：处理器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "是用来处理日志记录的类，它可以将`LogRecord`输出到我们指定的日志位置和存储形式等，如我们可以指定将日志通过`FTP`协议，记录到远程的服务器,`Handler`就会帮我们完成这些事情。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatter：格式器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际上生成的`LogRecord`也是一个个对象，那么我们想要把它们保存成一条条`日志文本`的话，就需要有一个`格式化的过程`，这个过程便是由`Formatter`来完成的，返回的便是`日志字符串`，然后再传回给`Handler`来处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter：过滤器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，保存日志的时候，我们可能不需要全部保存，只需要保存需要的部分就可以。因此，保存前还需要进行一下过滤，留下需要的日志，比如只保存某个级别的日志，或只保存包含某个关键字的日志等，这个**过滤过程**便是由`Filter`来完成的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParentHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Handler`之间可以存在分层关系，以使得不同`Handler`之间共享相同功能的代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logging模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logging模块比print的优势"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总的来说 logging 模块相比 print 有这么几个优点：\n",
    "1. 可以在 logging 模块中设置日志等级，在不同的版本（如开发环境、生产环境）上通过设置不同的输出等级来记录对应的日志，非常灵活\n",
    "2. print 的输出信息都会输出到标准输出流中，而 logging 模块就更加灵活，可以设置输出到任意位置，如写入文件、写入远程服务器等\n",
    "3. logging 模块具有灵活的配置和格式化功能，如配置输出当前模块信息、运行时间等，相比 print 的字符串格式化更加方便易用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logging模块五大组件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging.Logger()：日志器类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个`logging.Logger()`可以有多个`Handler()`，用于控制将不同级别的信息输出到不同的位置。我们只需要对多个不同的`Handler()`分别设置`setLevel(level)`，用以代表不同级别的日志，然后将其添加到`logging.Logger()`里即可,但是事实上，对于设置`level`的`Handler()`，它会把大于等于该`level`的信息输出，并不是纯粹的只有某个`level`的信息。如果想要控制输出到控制台的日志级别，需要设置`logging.Logger()`的`level`。同时必须注意`logRecord`的`level`，小于这个`level`的日志记录，并不产生，其设置地方在`logging.basicConfig(level)`\n",
    "\n",
    "Logger对象有3个任务要做：\n",
    "1. 向应用程序代码暴露几个方法，使应用程序可以在运行时记录日志消息；\n",
    "2. 基于日志严重等级（默认的过滤设施）或filter对象来决定要对哪些日志进行后续处理；\n",
    "3. 将日志消息传送给所有感兴趣的日志handlers。\n",
    "\n",
    "Logger对象最常用的方法分为两类：配置方法 和 消息发送方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 配置方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./image/logger1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 消息发送方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./image/logger2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取Logger对象：logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一种方法是通过`logging.Logger()`类来创建一个`Logger`类的实例，但是我们通常采用第二种方法`logging.getLogger()`。\n",
    "\n",
    "`logging.getLogger()`方法有一个可选参数`name`，该参数表示将要返回的日志器的名称标识，如果不提供该参数，则其值为'root'。若以相同的`name`参数值多次调用`logging.getLogger()`方法，将会返回指向同一个`Logger`对象的引用。\n",
    "\n",
    "多次使用，一定要注意避免创建多个`Logger`，否则会出现重复输出日志现象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logger的层级结构与有效等级的说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `logger`的名称是一个以'.'分割的层级结构，每个'.'后面的`logger`都是'.'前面的`logger`的`children`，例如，有一个名称为 `foo` 的`logger`，其它名称分别为 `foo.bar`, `foo.bar.baz` 和 `foo.bam`都是 `foo` 的后代\n",
    "\n",
    "\n",
    "2. `logger`有一个\"有效等级（`effective level`）\"的概念。如果一个`logger`上没有被明确设置一个`level`，那么该`logger`就是使用它`parent`的`level`;如果它的`parent`也没有明确设置`level`则继续向上查找`parent`的`parent`的有效`level`，依次类推，直到找到一个明确设置了`level`的祖先为止。需要说明的是，`root logger`总是会有一个明确的`level`设置（默认为 `WARNING`）。当决定是否去处理一个已发生的事件时，`logger`的有效等级将会被用来决定是否将该事件传递给该`logger`的`handlers`进行处理\n",
    "\n",
    "\n",
    "3. `child loggers`在完成对日志消息的处理后，默认会将日志消息传递给与它们的祖先`loggers`相关的`handlers`。因此，我们不必为一个应用程序中所使用的所有`loggers`定义和配置`handlers`，只需要为一个顶层的`logger`配置`handlers`，然后按照需要创建`child loggers`就可足够了。我们也可以通过将一个`logger`的`propagate`属性设置为`False`来关闭这种传递机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一个例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:06:58.351830Z",
     "start_time": "2019-04-22T02:06:58.345846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code/log1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/log1.py\n",
    "\n",
    "# _*_coding:utf-8 _*_\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# 创建Logger对象\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 下面是日志记录\n",
    "logger.info('This is a log info')\n",
    "logger.debug('Debugging')\n",
    "logger.warning('Warning exists')\n",
    "logger.info('Finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里我们首先引入了`logging`模块，然后进行了一下基本的配置，这里通过`logging.basicConfig`配置了 `level `信息和 `format` 信息，这里 `level` 配置为 `INFO` 信息，即只输出 `INFO` 级别的信息，另外这里指定了 `format` 格式的字符串，包括 `asctime`、`name`、`levelname`、`message` 四个内容，分别代表运行时间、模块名称、日志级别、日志内容，这样输出内容便是这四者组合而成的内容了，这就是 `logging` 的全局配置。\n",
    "\n",
    "接下来声明了一个 `Logger` 对象，它就是日志输出的主类，调用对象的 `info()` 方法就可以输出 `INFO` 级别的日志信息，调用 `debug()` 方法就可以输出 `DEBUG` 级别的日志信息，非常方便。\n",
    "\n",
    "在初始化的时候我们传入了**模块的名称**，这里直接使用 `__name__` 来代替了，就是**模块的名称**，如果直接运行这个脚本的话就是 `__main__`，如果是 `import` 的模块的话就是被引入模块的名称，这个变量在不同的模块中的名字是不同的，所以一般使用 `__name__` 来表示就好了，再接下来输出了四条日志信息，其中有两条 `INFO`、一条 `WARNING`、一条 `DEBUG` 信息，我们看下输出结果:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:06:58.365793Z",
     "start_time": "2019-04-22T02:06:58.355824Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-22 10:06:58,357 - __main__ - INFO - This is a log info\n",
      "2019-04-22 10:06:58,360 - __main__ - WARNING - Warning exists\n",
      "2019-04-22 10:06:58,361 - __main__ - INFO - Finish\n"
     ]
    }
   ],
   "source": [
    "%run ./code/log1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging.LogRecord()： 日志记录类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logging.LogRecord`对象通常会由`Logger`每次开始记录日志时自动创建，也可以通过函数`logging.makeLogRecord()`手动创建，它包含了与正在记录的事件相关的所有信息。\n",
    "\n",
    "一个`logging.LogRecord`对象对应了日志中的一行数据，该行数据通常包括：时间、日志级别、提示信息message、当前执行的模块、行号、函数名等等，这些信息都包含在`LogRecord`对象里，其参数具体如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logging.LogRecord(name,level,pathname,lineno,msg,args,exc_info,func,sinfo)`：\n",
    "\n",
    "1. name: 用于记录此LogRecord所表示事件的logger的名称\n",
    "2. level: 日志记录事件的等级\n",
    "3. pathname: logging调用时源文件的完整路径名\n",
    "4. lineno: logging调用时源文件的行号\n",
    "5. msg: 事件的描述信息\n",
    "6. args: 用于描述事件的，源文件中某个变量的值。这个参数与msg参数的使用方式是(msg='%d ...',args=value)\n",
    "7. exc_info: 具有当前异常信息的异常元组，如果没有可用的异常信息，则为None\n",
    "8. func: 日志发生时的 函数或方法的名字\n",
    "9. sinfo: 一个文本字符串，表示从当前线程的栈底到logging调用时的栈信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging.Handler()：处理器类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logging.Handler()`对象的作用是（基于日志消息的level）将消息分发到handler指定的位置（文件、网络、邮件等）。`Logger`对象可以通过`addHandler()`方法为自己添加0个或者更多个`Handler`对象。比如，一个应用程序可能想要实现以下几个日志需求：\n",
    "\n",
    "1. 把所有日志都发送到一个日志文件中；\n",
    "2. 把所有严重级别大于等于error的日志发送到stdout（标准输出）；\n",
    "3. 把所有严重级别为critical的日志发送到一个email邮件地址。这种场景就需要3个不同的handlers，每个handler负责发送一个特定严重级别的日志到一个特定的位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logging.Handler的子类和方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `logging.Handler.setLevel(lel)`: 指定被处理的信息级别，低于lel级别的信息将被忽略\n",
    "2. `logging.Handler.setFormatter(format)`：给这个handler选择一个格式\n",
    "3. `logging.Handler.addFilter(filt)`、`Handler.removeFilter(filt)`：新增或删除一个filter对象\n",
    "\n",
    "需要说明的是，应用程序代码不应该直接实例化和使用`logging.Handler`实例。因为`logging.Handler`是一个基类，它只定义了所有`logging.handlers`都应该有的接口，同时提供了一些子类可以直接使用或覆盖的默认行为。下面是一些常用的`logging.Handler`：\n",
    "\n",
    "![](./image/handler.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第一个例子：各个级别的日志输出到同一个地方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:06:58.385739Z",
     "start_time": "2019-04-22T02:06:58.370780Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-22 10:06:58,373 - __main__ - INFO - This is a log info\n",
      "2019-04-22 10:06:58,381 - __main__ - WARNING - Warning exists\n",
      "2019-04-22 10:06:58,381 - __main__ - INFO - Finsh\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(level=logging.INFO)\n",
    "handler = logging.FileHandler(filename='./code/output.log') # 日志输出路径\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.info('This is a log info')\n",
    "logger.debug('Debugging')\n",
    "logger.warning('Warning exists')\n",
    "logger.info('Finsh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们没有再使用`logging.basicConfig`全局配置，而是先声明了一个`Logger`对象，然后指定了其对应的`Handler`为`FileHandler`对象，然后`Handler`对象还单独指定了`Formatter`对象单独配置输出格式，最后给`Logger`对象添加对应的`Handler `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第二个例子：不同级别的日志输出到不同的地方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们使用三个`Handler`来实现日志同时输出到控制台、文件、HTTP服务器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:06.602457Z",
     "start_time": "2019-04-22T02:06:58.388733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a log info \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\logging\\handlers.py\", line 1195, in emit\n",
      "    h.endheaders()\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Anaconda3\\lib\\socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Anaconda3\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "Call stack:\n",
      "  File \"C:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n",
      "    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-0c6e58c28036>\", line 25, in <module>\n",
      "    logger.info('This is a log info ')\n",
      "Message: 'This is a log info '\n",
      "Arguments: ()\n",
      "2019-04-22 10:06:58,393 - __main__ - INFO - This is a log info \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\logging\\handlers.py\", line 1195, in emit\n",
      "    h.endheaders()\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Anaconda3\\lib\\socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Anaconda3\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "Call stack:\n",
      "  File \"C:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n",
      "    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-0c6e58c28036>\", line 26, in <module>\n",
      "    logger.debug('Debugging')\n",
      "Message: 'Debugging'\n",
      "Arguments: ()\n",
      "2019-04-22 10:07:00,455 - __main__ - DEBUG - Debugging\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\logging\\handlers.py\", line 1195, in emit\n",
      "    h.endheaders()\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Anaconda3\\lib\\socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Anaconda3\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "Call stack:\n",
      "  File \"C:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n",
      "    handle._run()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 12518 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "from logging.handlers import HTTPHandler\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(level=logging.DEBUG)\n",
    "\n",
    "# 输出DEBUG级别的日志 到 控制台\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "stream_handler.setLevel(level=logging.DEBUG)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "# 输出INFO级别的日志 到 文件\n",
    "file_handler = logging.FileHandler('./code/output2.log')\n",
    "file_handler.setLevel(level=logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') # 格式器\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# 输出日志到HTTP服务器\n",
    "http_handler = logging.handlers.HTTPHandler(host='localhost:8001',url='log',method='POST')\n",
    "logger.addHandler(http_handler)\n",
    "\n",
    "# 待输出的日志记录\n",
    "logger.info('This is a log info ')\n",
    "logger.debug('Debugging')\n",
    "logger.warning('Warning exists')\n",
    "logger.info('Finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行之前我们需要先启动 HTTP Server，并运行在 8001 端口，其中 log 接口是用来接收日志的接口。HTTP Server 会收到控制台输出的信息。这样一来，我们就通过设置多个 Handler 来控制了日志的多目标输出。\n",
    "\n",
    "另外值得注意的是，在这里 StreamHandler 对象我们没有设置 Formatter，因此控制台只输出了日志的内容，而没有包含时间、模块等信息，而 FileHandler 我们通过 setFormatter() 方法设置了一个 Formatter 对象，因此输出的内容便是格式化后的日志信息。\n",
    "\n",
    "<font color='red'>另外每个 Handler 还可以设置 level 信息，最终输出结果的 level 信息会取 Logger 对象的 level 和 Handler 对象的 level 的交集。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging.Filter()：过滤器类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提供了更细粒度的控制工具来决定输出哪条日志记录，丢弃哪条日志记录。\n",
    "\n",
    "`Filter`可以被`Handler`和`Logger`用来做比`level`更细粒度的、更复杂的`过滤功能`。`Filter`是一个`过滤器基类`，它只允许某个`logger层级`下的日志事件通过过滤。比如，一个`filter`实例化时传递的`name`参数值为`'A.B'`，那么该`filter`实例将只允许名称为类似如下规则的loggers产生的日志记录通过过滤：`'A.B'，'A.B,C'，'A.B.C.D'，'A.B.D'`，而名称为`'A.BB', 'B.A.B'`的loggers产生的日志则会被过滤掉。如果`name`的值为`空字符串`，则允许所有的日志事件通过过滤。\n",
    "\n",
    "`filter`方法用于具体控制传递的record记录是否能通过过滤，如果该方法返回值为0表示不能通过过滤，返回值为非0表示可以通过过滤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging.Formatter()：格式器类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Formater`对象用于配置日志信息的最终顺序、结构和内容，与`logging.Handler`基类不同的是，应用代码可以直接实例化`Formatter`类。另外，如果你的应用程序需要一些特殊的处理行为，也可以实现一个`Formatter`的子类来完成。\n",
    "　　\n",
    "可见，该构造方法接收3个可选参数：\n",
    "\n",
    "1. `fmt`：指定消息格式化字符串，如果不指定该参数则默认使用message的原始值\n",
    "2. `datefmt`：指定日期格式字符串，如果不指定该参数则默认使用\"%Y-%m-%d %H:%M:%S\"\n",
    "3. `style`：Python 3.2新增的参数，可取值为 '%', '{'和 '$'，如果不指定该参数则默认使用'%'\n",
    " \n",
    "一般直接用`logging.Formatter（fmt, datefmt）`，例如："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "\n",
    "import logging\n",
    "\n",
    "formatter = logging.Formatter(fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                             datefmt=\"%Y-%m-%d %H:%M:%S %a\" # %a表示星期几\n",
    "                             ) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 五大组件之间关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 日志器（logger）需要通过处理器（handler）将日志信息LogRecord输出到目标位置，如：文件、sys.stdout、网络等\n",
    "2. 不同的处理器（handler）可以将日志LogRecord输出到不同的位置\n",
    "3. 日志器（logger）可以设置多个处理器（handler）将同一条日志记录LogRecord输出到不同的位置\n",
    "4. 每个处理器（handler）都可以设置自己的过滤器（filter）实现日志过滤，从而只保留感兴趣的日志\n",
    "5. 每个处理器（handler）都可以设置自己的格式器（formatter）实现同一条日志以不同的格式输出到不同的地方\n",
    "\n",
    "简单点说就是：日志器（logger）是入口，真正干活儿的是处理器（handler），处理器（handler）还可以通过过滤器（filter）和格式器（formatter）对要输出的日志内容做过滤和格式化等处理操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logging模块创建日志记录的函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置日志器的级别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>注意，我们不仅要设置 日志记录的level，还要设置logger日志器的level,并且具体输出什么等级的日志记录，由两者共同决定！</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:06.612427Z",
     "start_time": "2019-04-22T02:07:06.606449Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger() # 创建日志器logger\n",
    "logger.setLevel(level=0) # 设置logger的level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置日志记录的级别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logging.basicConfig()中的参数level ，便是用于设置日志记录的级别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./image/logging_logrecord.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:06.629383Z",
     "start_time": "2019-04-22T02:07:06.616417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code/log2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/log2.py\n",
    "# _*_coding:utf-8 _*_\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger() # 获取日志器logger\n",
    "logger.setLevel(level=0) # 设置logger的level\n",
    "\n",
    "# 在代码中需要输出相应级别的日志的地方，设置如下代码\n",
    "# 以下都是日志记录的level\n",
    "logging.debug('debug_msg')\n",
    "logging.info('info_msg')\n",
    "logging.warning('warning_msg')\n",
    "logging.error('error_msg')\n",
    "logging.critical('critical_msg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:06.646337Z",
     "start_time": "2019-04-22T02:07:06.631379Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-22 10:07:06,636 - root - DEBUG - debug_msg\n",
      "2019-04-22 10:07:06,637 - root - INFO - info_msg\n",
      "2019-04-22 10:07:06,638 - root - WARNING - warning_msg\n",
      "2019-04-22 10:07:06,639 - root - ERROR - error_msg\n",
      "2019-04-22 10:07:06,642 - root - CRITICAL - critical_msg\n"
     ]
    }
   ],
   "source": [
    "%run ./code/log2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:06.653318Z",
     "start_time": "2019-04-22T02:07:06.649330Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.log(level=0,msg='This is NOTSE message') # 参数level必须是日志等级所对应的数值，参数msg是相应的日志文本信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logging.basicConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logging.basicConfig()函数用来对日志级别和日志记录的输出格式做基本的配置，其参数说明如下：\n",
    "\n",
    "![](./image/logging_basicConfig.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:06.660307Z",
     "start_time": "2019-04-22T02:07:06.655313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code/log3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/log3.py\n",
    "# _*_coding:utf-8 _*_\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger() # 获取日志器logger\n",
    "logger.setLevel(level=0) # 设置logger的level\n",
    "\n",
    "LOG_FORMAT = \"%(asctime)s %(name)s %(levelname)s %(pathname)s %(message)s \"#配置输出日志格式\n",
    "DATE_FORMAT = '%Y-%m-%d  %H:%M:%S %a ' #配置输出时间的格式，注意月份和天数不要搞乱了\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,# 设置输出的日志级别，大于等于DEBUG级别的日志记录都会输出\n",
    "                   format= LOG_FORMAT,\n",
    "                    datefmt=DATE_FORMAT,\n",
    "                    filename = \"./code/test.log\" # 设置日志输出的文件名及其路径\n",
    "                   )\n",
    "\n",
    "logging.debug('msg1')\n",
    "logging.info('msg2')\n",
    "logging.warning('msg3')\n",
    "logging.error('msg4')\n",
    "logging.critical('msg5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:06.673265Z",
     "start_time": "2019-04-22T02:07:06.662295Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-22 10:07:06,665 - root - DEBUG - msg1\n",
      "2019-04-22 10:07:06,666 - root - INFO - msg2\n",
      "2019-04-22 10:07:06,667 - root - WARNING - msg3\n",
      "2019-04-22 10:07:06,668 - root - ERROR - msg4\n",
      "2019-04-22 10:07:06,669 - root - CRITICAL - msg5\n"
     ]
    }
   ],
   "source": [
    "%run ./code/log3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：\n",
    "1. logging.basicConfig()函数是一个一次性的简单配置工具，也就是说只有在第一次调用该函数时会起作用，后续再次调用该函数时完全不会产生任何操作的，多次调用的设置并不是累加操作\n",
    "2. 日志器（Logger）是有层级关系的，上面调用的logging模块级别的函数所使用的日志器是RootLogger类的实例，其名称为'root'，它是处于日志器层级关系最顶层的日志器，且该实例是以单例模式存在的\n",
    "\n",
    "如果要记录的日志中包含**变量数据**，可使用一个**格式字符串**作为这个事件的描述消息（logging.debug、logging.info等函数的第一个参数），然后将**变量数据**作为第二个参数*args的值进行传递\n",
    "\n",
    "如：\n",
    "```Python\n",
    "logging.warning('%s is %d years old.', 'Tom', 10)\n",
    "\n",
    "输出内容：\n",
    "\n",
    "WARNING:root:Tom is 10 years old.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 捕获Traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果遇到错误，我们更希望报错时出现的详细 Traceback 信息，便于调试，利用 logging 模块我们可以非常方便地实现这个记录，我们用一个实例来感受一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:14.829134Z",
     "start_time": "2019-04-22T02:07:06.675259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\logging\\handlers.py\", line 1195, in emit\n",
      "    h.endheaders()\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Anaconda3\\lib\\socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Anaconda3\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "Call stack:\n",
      "  File \"C:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n",
      "    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-9f7e9060493a>\", line 20, in <module>\n",
      "    logger.info('Start')\n",
      "Message: 'Start'\n",
      "Arguments: ()\n",
      "2019-04-22 10:07:06,680 - __main__ - INFO - Start\n",
      "2019-04-22 10:07:06,680 - __main__ - INFO - Start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something maybe fail.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\logging\\handlers.py\", line 1195, in emit\n",
      "    h.endheaders()\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Anaconda3\\lib\\socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Anaconda3\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "Call stack:\n",
      "  File \"C:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n",
      "    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-9f7e9060493a>\", line 21, in <module>\n",
      "    logger.warning('Something maybe fail.')\n",
      "Message: 'Something maybe fail.'\n",
      "Arguments: ()\n",
      "2019-04-22 10:07:08,715 - __main__ - WARNING - Something maybe fail.\n",
      "2019-04-22 10:07:08,715 - __main__ - WARNING - Something maybe fail.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get result\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-9f7e9060493a>\", line 23, in <module>\n",
      "    result = 10 / 0\n",
      "ZeroDivisionError: division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-9f7e9060493a>\", line 23, in <module>\n",
      "    result = 10 / 0\n",
      "ZeroDivisionError: division by zero\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\logging\\handlers.py\", line 1195, in emit\n",
      "    h.endheaders()\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Anaconda3\\lib\\socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Anaconda3\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "Call stack:\n",
      "  File \"C:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Anaconda3\\lib\\site-package"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 13202 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(level=logging.DEBUG)\n",
    "\n",
    "# Formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "#FileHandler\n",
    "file_handler = logging.FileHandler('./code/result.log')\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# StreamHandler\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "# log\n",
    "logger.info('Start')\n",
    "logger.warning('Something maybe fail.')\n",
    "try:\n",
    "    result = 10 / 0\n",
    "except Exception:\n",
    "    logger.error('Failed to get result',exc_info=True)\n",
    "logger.info('Finshed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们在 `logging.error() `方法中添加了一个参数，将 `exc_info` 设置为了 `True`，这样我们就可以输出执行过程中的信息了，即完整的 `Traceback` 信息,具体日志信息可查看文件 `./code/result.log`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logging模块中format格式字符串说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./image/logging_format.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](logging_format.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日志记录的配置文件设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置共享: 用于多模块文件日志的记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在写项目的时候，我们肯定会将许多配置放置在许多模块下面，这时如果我们每个文件都来配置 `logging` 配置那就太繁琐了，`logging` 模块提供了**父子模块共享配置的机制**，会根据` Logger `的**名称**来自动加载**父模块的配置**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义父模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:14.839107Z",
     "start_time": "2019-04-22T02:07:14.832124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/main.py\n",
    "# _*_coding:utf-8 _*_\n",
    "\n",
    "import logging\n",
    "import core # 子模块\n",
    "\n",
    "logger = logging.getLogger('main')\n",
    "logger.setLevel(level=logging.DEBUG)\n",
    "\n",
    "# Handler\n",
    "handler = logging.FileHandler('./code/common.log')\n",
    "handler.setLevel(logging.INFO)\n",
    "\n",
    "# Formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.info('Main Info')\n",
    "logger.debug('Main Debug')\n",
    "logger.error('Main Error')\n",
    "core.run() # 调用子模块方法，同时开始记录子模块日志信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们配置了日志的输出格式和文件路径，同时定义了 `Logger` 的名称为 `main`，然后引入了另外一个模块 `core`，最后调用了 `core` 的 `run()` 方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义子模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.139914Z",
     "start_time": "2019-04-22T02:07:14.842097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/core.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/core.py\n",
    "# _*_coding:utf-8 _*_\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger('main.core') # 子模块的Logger，会复用主模块的Logger的配置\n",
    "\n",
    "def run():\n",
    "    logger.info('Core Info')\n",
    "    logger.debug('Core Debug')\n",
    "    logger.error('Core Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们定义了 `Logger` 的名称为 `main.core`，注意这里开头是` main`，即刚才我们在 `main.py` 里面的` Logger` 的名称，这样 `core.py` 里面的 `Logger` 就会复用` main.py `里面的` Logger `配置，而不用再去配置一次了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 同时记录父子模块的日志信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.578792Z",
     "start_time": "2019-04-22T02:07:15.145898Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-22 10:07:15,551 - main - INFO - Main Info\n",
      "2019-04-22 10:07:15,553 - main - DEBUG - Main Debug\n",
      "2019-04-22 10:07:15,557 - main - ERROR - Main Error\n",
      "2019-04-22 10:07:15,560 - main.core - INFO - Core Info\n",
      "2019-04-22 10:07:15,565 - main.core - DEBUG - Core Debug\n",
      "2019-04-22 10:07:15,567 - main.core - ERROR - Core Error\n"
     ]
    }
   ],
   "source": [
    "%run ./code/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果同时可查看`./code/common.log`文件，可以看到父子模块都使用了同样的输出配置。\n",
    "\n",
    "如此一来，我们只要在**入口文件**里面定义好 `logging` 模块的输出配置，**子模块**只需要在定义 `Logger` 对象时，**名称使用父模块的名称开头即可共享配置**，非常方便。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logging读取配置文件: logging.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging.config.dictConfig(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logging.config.dictConfig(config)`可以从字典类型的对象和配置文件中获取配置：\n",
    "1. config: 是一个字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.592754Z",
     "start_time": "2019-04-22T02:07:15.583779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code/test.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/test.yaml\n",
    "version: 1\n",
    "formatters:\n",
    "  simple:\n",
    "    format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "handlers:\n",
    "  console:\n",
    "    class: logging.StreamHandler\n",
    "    level: DEBUG\n",
    "    formatter: simple\n",
    "  \n",
    "loggers:\n",
    "  simpleExample:\n",
    "    level: DEBUG\n",
    "    handlers: [console]\n",
    "    propagate: no\n",
    "root:\n",
    "  level: DEBUG\n",
    "  handlers: [console]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.635639Z",
     "start_time": "2019-04-22T02:07:15.595747Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取yaml格式的文件\n",
    "# 需要按照 pyyaml 库\n",
    "import yaml\n",
    "\n",
    "with open('./code/test.yaml','r') as fi:\n",
    "    config = yaml.safe_load(fi.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.653591Z",
     "start_time": "2019-04-22T02:07:15.637634Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-22 10:07:15,649 - sampleLogger - DEBUG - this is a debug \n"
     ]
    }
   ],
   "source": [
    "import logging.config\n",
    "\n",
    "logging.config.dictConfig(config)\n",
    "logger = logging.getLogger('sampleLogger')\n",
    "\n",
    "logger.debug('this is a debug ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging.config.fileConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logging.config.fileConfig(fname,defaults=None,disable_existing_loggers=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ini`格式的配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.663565Z",
     "start_time": "2019-04-22T02:07:15.655586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code/test.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/test.ini\n",
    "\n",
    "[loggers]\n",
    "keys=root,sampleLogger\n",
    "\n",
    "[handlers]\n",
    "keys=consoleHandler\n",
    "\n",
    "[formatters]\n",
    "keys=sampleFormatter\n",
    "\n",
    "[logger_root]\n",
    "level=DEBUG\n",
    "handlers=consoleHandler\n",
    "\n",
    "[logger_sampleLogger]\n",
    "level=DEBUG\n",
    "handlers=consoleHandler\n",
    "qualname=sampleLogger\n",
    "propagate=0\n",
    "\n",
    "[handler_consoleHandler]\n",
    "class=StreamHandler\n",
    "level=DEBUG\n",
    "formatter=sampleFormatter\n",
    "args=(sys.stdout,)\n",
    "\n",
    "[formatter_sampleFormatter]\n",
    "format=%(asctime)s - %(name)s - %(levelname)s - %(message)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.682515Z",
     "start_time": "2019-04-22T02:07:15.667555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-22 10:07:15,677 - sampleLogger - INFO - this is a info \n"
     ]
    }
   ],
   "source": [
    "import logging.config\n",
    "\n",
    "# 读取配置文件\n",
    "logging.config.fileConfig(fname='./code/test.ini',disable_existing_loggers=False)\n",
    "logger = logging.getLogger('sampleLogger')\n",
    "\n",
    "logger.info('this is a info ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置文件的构成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置文件主要包含以下几部分：\n",
    "\n",
    "1. `loggers` : 配置logger信息。必须包含一个名字叫做root的logger，当使用无参函数logging.getLogger()时，默认返回root这个logger，其他自定义logger可以通过 logging.getLogger(\"fileLogger\") 方式进行调用\n",
    "\n",
    "\n",
    "2. `handlers`: 定义声明handlers信息。常用的handlers包括 StreamHandler（仅将日志输出到控制台）、FileHandler（将日志信息输出保存到文件）、RotaRotatingFileHandler（将日志输出保存到文件中，并设置单个日志文件的大小和日志文件个数）\n",
    "\n",
    "\n",
    "3. `formatter` : 设置日志格式\n",
    "\n",
    "\n",
    "4. `logger_xxx` : 对loggers中声明的logger进行逐个配置，且要一一对应\n",
    "\\\n",
    "\n",
    "5. `handler_xxx` : 对handlers中声明的handler进行逐个配置，且要一一对应\n",
    "\n",
    "\n",
    "6. `formatter_xxx` : 对声明的formatter进行配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在开发过程中，将配置在代码里面写死并不是一个好的习惯，更好的做法是将配置写在**配置文件**里面，我们可以将配置写入到配置文件，然后运行时读取配置文件里面的配置，这样是更方便管理和维护的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ini型配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.690493Z",
     "start_time": "2019-04-22T02:07:15.684509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code/logging_test.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/logging_test.ini\n",
    "[loggers]\n",
    "keys=root,sampleLogger\n",
    "\n",
    "[handlers]\n",
    "keys=consoleHandler\n",
    "\n",
    "[formatters]\n",
    "keys=sampleFormatter\n",
    "\n",
    "[logger_root]\n",
    "level=DEBUG\n",
    "handlers=consoleHandler\n",
    "\n",
    "[logger_sampleLogger]\n",
    "level=DEBUG\n",
    "handlers=consoleHandler\n",
    "qualname=sampleLogger\n",
    "propagate=0\n",
    "\n",
    "[handler_consoleHandler]\n",
    "class=StreamHandler\n",
    "level=DEBUG\n",
    "formatter=sampleFormatter\n",
    "args=(sys.stdout,)\n",
    "\n",
    "[formatter_sampleFormatter]\n",
    "format=%(asctime)s - %(name)s - %(levelname)s - %(message)s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yaml型配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.706451Z",
     "start_time": "2019-04-22T02:07:15.699469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code/logging_test.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/logging_test.yaml\n",
    "version: 1\n",
    "formatters:\n",
    "  simple:\n",
    "    format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "handlers:\n",
    "  console:\n",
    "    class: logging.StreamHandler\n",
    "    level: DEBUG\n",
    "    formatter: simple\n",
    "  \n",
    "loggers:\n",
    "  simpleExample:\n",
    "    level: DEBUG\n",
    "    handlers: [console]\n",
    "    propagate: no\n",
    "root:\n",
    "  level: DEBUG\n",
    "  handlers: [console]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON型配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.717420Z",
     "start_time": "2019-04-22T02:07:15.710440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code/logging_test.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/logging_test.json\n",
    "{\n",
    "    'version': 1,\n",
    "    'formatters': {\n",
    "        'simple': {\n",
    "            'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        },\n",
    "        # 其他的 formatter\n",
    "    },\n",
    "    'handlers': {\n",
    "        'console': {\n",
    "            'class': 'logging.StreamHandler',\n",
    "            'level': 'DEBUG',\n",
    "            'formatter': 'simple'\n",
    "        },\n",
    "        'file': {\n",
    "            'class': 'logging.FileHandler',\n",
    "            'filename': 'logging.log',\n",
    "            'level': 'DEBUG',\n",
    "            'formatter': 'simple'\n",
    "        },\n",
    "        # 其他的 handler\n",
    "    },\n",
    "    'loggers':{\n",
    "        'StreamLogger': {\n",
    "            'handlers': ['console'],\n",
    "            'level': 'DEBUG',\n",
    "        },\n",
    "        'FileLogger': {\n",
    "            # 既有 console Handler，还有 file Handler\n",
    "            'handlers': ['console', 'file'],\n",
    "            'level': 'DEBUG',\n",
    "        },\n",
    "        # 其他的 Logger\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建JSON配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.745346Z",
     "start_time": "2019-04-22T02:07:15.720413Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'version': 1,\n",
    "    'formatters': {\n",
    "        'simple': {\n",
    "            'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        },\n",
    "        # 其他的 formatter\n",
    "    },\n",
    "    'handlers': {\n",
    "        'console': {\n",
    "            'class': 'logging.StreamHandler',\n",
    "            'level': 'DEBUG',\n",
    "            'formatter': 'simple'\n",
    "        },\n",
    "        'file': {\n",
    "            'class': 'logging.FileHandler',\n",
    "            'filename': 'logging.log',\n",
    "            'level': 'DEBUG',\n",
    "            'formatter': 'simple'\n",
    "        },\n",
    "        # 其他的 handler\n",
    "    },\n",
    "    'loggers':{\n",
    "        'StreamLogger': {\n",
    "            'handlers': ['console'],\n",
    "            'level': 'DEBUG',\n",
    "        },\n",
    "        'FileLogger': {\n",
    "            # 既有 console Handler，还有 file Handler\n",
    "            'handlers': ['console', 'file'],\n",
    "            'level': 'DEBUG',\n",
    "        },\n",
    "        # 其他的 Logger\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('./code/test.json','w',encoding='utf-8') as fi:\n",
    "    import json\n",
    "    json.dump(config,fi,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.757317Z",
     "start_time": "2019-04-22T02:07:15.747341Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-22 10:07:15,752 - StreamLogger - DEBUG - this is a debug \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "2019-04-22 10:07:15,752 - StreamLogger - DEBUG - this is a debug \n"
     ]
    }
   ],
   "source": [
    "import logging.config\n",
    "import json\n",
    "\n",
    "with open('./code/test.json','r',encoding='utf-8') as fi:\n",
    "    config = json.load(fi)\n",
    "print(type(config))\n",
    "logging.config.dictConfig(config)\n",
    "logger = logging.getLogger('StreamLogger')\n",
    "filelogger = logging.getLogger('FileLogger')\n",
    "\n",
    "logger.debug('this is a debug ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日志记录的误区"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日志记录的书写方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在日志输出的时候经常我们会用到**字符串拼接的形式**，很多情况下我们可能会使用字符串的 `format()` 来构造一个字符串，但这其实并**不是一个好的方法**，因为还有更好的方法，下面我们对比两个例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.766290Z",
     "start_time": "2019-04-22T02:07:15.759309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-22 10:07:15,761 - root - DEBUG - Hello World, Congratulations!\n",
      "2019-04-22 10:07:15,762 - root - DEBUG - Hello World, Congratulations!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    " \n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    " \n",
    "# bad\n",
    "logging.debug('Hello {0}, {1}!'.format('World', 'Congratulations'))\n",
    "# good\n",
    "logging.debug('Hello %s, %s!', 'World', 'Congratulations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里有两种打印 `Log` 的方法:\n",
    "1. 第一种使用了字符串的 format() 的方法进行构造，传给 logging 的只用到了第一个参数\n",
    "2. 实际上 logging 模块提供了字符串格式化的方法，我们只需要在第一个参数写上**要打印输出的模板**，**占位符用 %s、%d 等表示即可**，然后**在后续参数添加对应的值就可以了**，推荐使用这种方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 记录程序异常Traceback日志"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外在进行异常处理的时候，通常我们会直接将异常进行字符串格式化，但其实可以直接指定一个参数将 traceback 打印出来，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:15.778259Z",
     "start_time": "2019-04-22T02:07:15.768286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-22 10:07:15,771 - root - ERROR - Error: division by zero\n",
      "2019-04-22 10:07:15,773 - root - ERROR - Error\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-26-b83145e81bf4>\", line 6, in <module>\n",
      "    result = 5 / 0\n",
      "ZeroDivisionError: division by zero\n",
      "2019-04-22 10:07:15,774 - root - ERROR - Error\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-26-b83145e81bf4>\", line 6, in <module>\n",
      "    result = 5 / 0\n",
      "ZeroDivisionError: division by zero\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "try:\n",
    "    result = 5 / 0\n",
    "except Exception as e:\n",
    "    # bad\n",
    "    logging.error('Error: %s',e)\n",
    "    # good\n",
    "    logging.error('Error',exc_info=True)\n",
    "    # good\n",
    "    logging.exception('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们直接使用字符串格式化的方法将错误输出的话，是不会包含 `Traceback `信息的，但如果我们加上 `exc_info` 参数或者直接使用` exception() `方法打印的话，那就会输出` Traceback `信息了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日志回滚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概念理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将日志信息输出到一个单一的文件中，随着应用程序的持续使用，该日志文件会越来越庞大，进而影响系统性能。因此，有必要对日志文件按某种条件进行切分，切分日志的**触发条件**是：\n",
    "1. 大小\n",
    "2. 日期\n",
    "3. 大小 + 日期\n",
    "\n",
    "所谓**切分**，是指当一个日志文件达到触发条件后，便对日志文件进行重命名，然后再新建一个和原日志名称相同的空日志文件，新产生的日志便写入该文件中。\n",
    "\n",
    "所谓**回滚**，是指当分割的日志文件达到指定数目的上限个数时，最老的日志文件会被删除。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照时间回滚，并以时间作为日志文件名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就是按时间分割日志，并且限制日志文件的个数，删除早期的日志。\n",
    "\n",
    "使用`logging.handlers.TimedRotatingFileHandler`，对log，通常有一种想要的效果：log按天切分，每天一个log文件，保留三天内的log，过期删除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logging.handlers.TimedRotatingFileHandler(filename,when,interval,backupCount)`\n",
    "1. filename : 输出日志文件名的前缀，包含路径，比如./code/myapp.log\n",
    "2. when: 是一个字符串，有如下可选值：\n",
    "    1. \"S\" : Seconds\n",
    "    2. \"M\": Minutes\n",
    "    3. \"H\": Hours\n",
    "    4. \"D\": Days\n",
    "    5. \"W\": Week day (0=Monday)\n",
    "    6. \"midnight\": Roll over at midnight\n",
    "3. interval: 指等待多少个单位when的时间后，Logger会自动重建日志文件。当然，这个日志文件的创建取决于 filename+suffix，若这个文件跟之前的文件有重名，则会自动覆盖掉以前的文件\n",
    "4. backupCount: 是保留日志文件的个数，默认的0是不会自动删除掉日志的。若设为3，则在文件的创建过程中，会判断是否有超过这个3，若超过，则会从最先创建的开始删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:17.286647Z",
     "start_time": "2019-04-22T02:07:15.780253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-22 10:07:15,885 - myapp - INFO - test\n",
      "2019-04-22 10:07:15,990 - myapp - INFO - test\n",
      "2019-04-22 10:07:16,096 - myapp - INFO - test\n",
      "2019-04-22 10:07:16,200 - myapp - INFO - test\n",
      "2019-04-22 10:07:16,302 - myapp - INFO - test\n",
      "2019-04-22 10:07:16,404 - myapp - INFO - test\n",
      "2019-04-22 10:07:16,515 - myapp - INFO - test\n",
      "2019-04-22 10:07:16,625 - myapp - INFO - test\n",
      "2019-04-22 10:07:16,729 - myapp - INFO - test\n",
      "2019-04-22 10:07:16,832 - myapp - INFO - test\n",
      "2019-04-22 10:07:16,948 - myapp - INFO - test\n",
      "2019-04-22 10:07:17,055 - myapp - INFO - test\n",
      "2019-04-22 10:07:17,165 - myapp - INFO - test\n",
      "2019-04-22 10:07:17,267 - myapp - INFO - test\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "# logging初始化工作\n",
    "logging.basicConfig()\n",
    "\n",
    "# myapp的初始化工作\n",
    "logger = logging.getLogger('myapp')\n",
    "logger.setLevel(level=logging.DEBUG)\n",
    "\n",
    "# 添加TimedRotatingFileHandler\n",
    "# 定义一个1秒换一次log文件的handler\n",
    "# 保留3个旧log文件\n",
    "timefilehandler = logging.handlers.TimedRotatingFileHandler(filename='./code/myapp.log',when='S',interval=1,backupCount=3)\n",
    "# 设置日志文件后缀名称，跟strftime的格式一样\n",
    "timefilehandler.suffix = \"%Y-%m-%d_%H-%M-%S.log\"\n",
    " \n",
    "formatter = logging.Formatter('%(asctime)s|%(name)-12s: %(levelname)-8s %(message)s')\n",
    "timefilehandler.setFormatter(formatter)\n",
    "logger.addHandler(timefilehandler)\n",
    " \n",
    "count = 1\n",
    "while count < 15:\n",
    "    time.sleep(0.1)\n",
    "    logger.info(\"test\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：`filehanlder.suffix`的格式必须这么写，才能自动删除旧文件，如果设定是天，就必须写成“%Y-%m-%d.log”，写成其他格式会导致删除旧文件不生效"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照日志文件大小回滚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logging.handlers.RotatingFileHandler(filename,maxBytes,backupCount)`基于文件大小切分:\n",
    "1. filename：  输出日志文件名的前缀，包含路径，比如./code/myapp.log\n",
    "2. maxBytes: 每个日志文件最大的大小\n",
    "3. backupCount: 保留多少个最新的日志文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:07:28.261175Z",
     "start_time": "2019-04-22T02:07:17.293629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-22 10:07:17,402 - myapp - INFO - file test\n",
      "2019-04-22 10:07:17,511 - myapp - INFO - file test\n",
      "2019-04-22 10:07:17,614 - myapp - INFO - file test\n",
      "2019-04-22 10:07:17,716 - myapp - INFO - file test\n",
      "2019-04-22 10:07:17,817 - myapp - INFO - file test\n",
      "2019-04-22 10:07:17,925 - myapp - INFO - file test\n",
      "2019-04-22 10:07:18,065 - myapp - INFO - file test\n",
      "2019-04-22 10:07:18,166 - myapp - INFO - file test\n",
      "2019-04-22 10:07:18,276 - myapp - INFO - file test\n",
      "2019-04-22 10:07:18,396 - myapp - INFO - file test\n",
      "2019-04-22 10:07:18,498 - myapp - INFO - file test\n",
      "2019-04-22 10:07:18,603 - myapp - INFO - file test\n",
      "2019-04-22 10:07:18,715 - myapp - INFO - file test\n",
      "2019-04-22 10:07:18,825 - myapp - INFO - file test\n",
      "2019-04-22 10:07:18,946 - myapp - INFO - file test\n",
      "2019-04-22 10:07:19,055 - myapp - INFO - file test\n",
      "2019-04-22 10:07:19,165 - myapp - INFO - file test\n",
      "2019-04-22 10:07:19,275 - myapp - INFO - file test\n",
      "2019-04-22 10:07:19,395 - myapp - INFO - file test\n",
      "2019-04-22 10:07:19,509 - myapp - INFO - file test\n",
      "2019-04-22 10:07:19,613 - myapp - INFO - file test\n",
      "2019-04-22 10:07:19,716 - myapp - INFO - file test\n",
      "2019-04-22 10:07:19,826 - myapp - INFO - file test\n",
      "2019-04-22 10:07:19,935 - myapp - INFO - file test\n",
      "2019-04-22 10:07:20,055 - myapp - INFO - file test\n",
      "2019-04-22 10:07:20,165 - myapp - INFO - file test\n",
      "2019-04-22 10:07:20,279 - myapp - INFO - file test\n",
      "2019-04-22 10:07:20,388 - myapp - INFO - file test\n",
      "2019-04-22 10:07:20,493 - myapp - INFO - file test\n",
      "2019-04-22 10:07:20,605 - myapp - INFO - file test\n",
      "2019-04-22 10:07:20,735 - myapp - INFO - file test\n",
      "2019-04-22 10:07:20,855 - myapp - INFO - file test\n",
      "2019-04-22 10:07:20,969 - myapp - INFO - file test\n",
      "2019-04-22 10:07:21,080 - myapp - INFO - file test\n",
      "2019-04-22 10:07:21,197 - myapp - INFO - file test\n",
      "2019-04-22 10:07:21,307 - myapp - INFO - file test\n",
      "2019-04-22 10:07:21,407 - myapp - INFO - file test\n",
      "2019-04-22 10:07:21,509 - myapp - INFO - file test\n",
      "2019-04-22 10:07:21,641 - myapp - INFO - file test\n",
      "2019-04-22 10:07:21,745 - myapp - INFO - file test\n",
      "2019-04-22 10:07:21,875 - myapp - INFO - file test\n",
      "2019-04-22 10:07:21,979 - myapp - INFO - file test\n",
      "2019-04-22 10:07:22,092 - myapp - INFO - file test\n",
      "2019-04-22 10:07:22,196 - myapp - INFO - file test\n",
      "2019-04-22 10:07:22,299 - myapp - INFO - file test\n",
      "2019-04-22 10:07:22,402 - myapp - INFO - file test\n",
      "2019-04-22 10:07:22,515 - myapp - INFO - file test\n",
      "2019-04-22 10:07:22,635 - myapp - INFO - file test\n",
      "2019-04-22 10:07:22,738 - myapp - INFO - file test\n",
      "2019-04-22 10:07:22,843 - myapp - INFO - file test\n",
      "2019-04-22 10:07:22,946 - myapp - INFO - file test\n",
      "2019-04-22 10:07:23,061 - myapp - INFO - file test\n",
      "2019-04-22 10:07:23,165 - myapp - INFO - file test\n",
      "2019-04-22 10:07:23,275 - myapp - INFO - file test\n",
      "2019-04-22 10:07:23,405 - myapp - INFO - file test\n",
      "2019-04-22 10:07:23,506 - myapp - INFO - file test\n",
      "2019-04-22 10:07:23,615 - myapp - INFO - file test\n",
      "2019-04-22 10:07:23,735 - myapp - INFO - file test\n",
      "2019-04-22 10:07:23,845 - myapp - INFO - file test\n",
      "2019-04-22 10:07:23,946 - myapp - INFO - file test\n",
      "2019-04-22 10:07:24,056 - myapp - INFO - file test\n",
      "2019-04-22 10:07:24,168 - myapp - INFO - file test\n",
      "2019-04-22 10:07:24,295 - myapp - INFO - file test\n",
      "2019-04-22 10:07:24,396 - myapp - INFO - file test\n",
      "2019-04-22 10:07:24,499 - myapp - INFO - file test\n",
      "2019-04-22 10:07:24,602 - myapp - INFO - file test\n",
      "2019-04-22 10:07:24,706 - myapp - INFO - file test\n",
      "2019-04-22 10:07:24,810 - myapp - INFO - file test\n",
      "2019-04-22 10:07:24,950 - myapp - INFO - file test\n",
      "2019-04-22 10:07:25,056 - myapp - INFO - file test\n",
      "2019-04-22 10:07:25,165 - myapp - INFO - file test\n",
      "2019-04-22 10:07:25,286 - myapp - INFO - file test\n",
      "2019-04-22 10:07:25,395 - myapp - INFO - file test\n",
      "2019-04-22 10:07:25,506 - myapp - INFO - file test\n",
      "2019-04-22 10:07:25,626 - myapp - INFO - file test\n",
      "2019-04-22 10:07:25,736 - myapp - INFO - file test\n",
      "2019-04-22 10:07:25,847 - myapp - INFO - file test\n",
      "2019-04-22 10:07:25,965 - myapp - INFO - file test\n",
      "2019-04-22 10:07:26,068 - myapp - INFO - file test\n",
      "2019-04-22 10:07:26,174 - myapp - INFO - file test\n",
      "2019-04-22 10:07:26,278 - myapp - INFO - file test\n",
      "2019-04-22 10:07:26,395 - myapp - INFO - file test\n",
      "2019-04-22 10:07:26,505 - myapp - INFO - file test\n",
      "2019-04-22 10:07:26,625 - myapp - INFO - file test\n",
      "2019-04-22 10:07:26,725 - myapp - INFO - file test\n",
      "2019-04-22 10:07:26,835 - myapp - INFO - file test\n",
      "2019-04-22 10:07:26,945 - myapp - INFO - file test\n",
      "2019-04-22 10:07:27,052 - myapp - INFO - file test\n",
      "2019-04-22 10:07:27,177 - myapp - INFO - file test\n",
      "2019-04-22 10:07:27,289 - myapp - INFO - file test\n",
      "2019-04-22 10:07:27,394 - myapp - INFO - file test\n",
      "2019-04-22 10:07:27,496 - myapp - INFO - file test\n",
      "2019-04-22 10:07:27,605 - myapp - INFO - file test\n",
      "2019-04-22 10:07:27,715 - myapp - INFO - file test\n",
      "2019-04-22 10:07:27,825 - myapp - INFO - file test\n",
      "2019-04-22 10:07:27,939 - myapp - INFO - file test\n",
      "2019-04-22 10:07:28,050 - myapp - INFO - file test\n",
      "2019-04-22 10:07:28,154 - myapp - INFO - file test\n",
      "2019-04-22 10:07:28,257 - myapp - INFO - file test\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import logging\n",
    "import logging.handlers\n",
    " \n",
    "# logging初始化工作  \n",
    "logging.basicConfig()\n",
    " \n",
    "# myapp的初始化工作  \n",
    "logger = logging.getLogger('myapp')\n",
    "logger.setLevel(logging.INFO)\n",
    " \n",
    "# 写入文件，如果文件超过100个Bytes，仅保留5个文件。  \n",
    "handler = logging.handlers.RotatingFileHandler('./code/myapp2.log', maxBytes=500, backupCount=5)\n",
    " \n",
    "formatter = logging.Formatter('%(asctime)s|%(name)-12s: %(levelname)-8s %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "# 设置后缀名称，跟strftime的格式一样  \n",
    "logger.addHandler(handler)\n",
    "\n",
    "count = 1\n",
    "while count < 100:\n",
    "    time.sleep(0.1)\n",
    "    logger.info(\"file test\")\n",
    "    count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
