{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文学习于[imbalanced-learn User Guide](https://imbalanced-learn.org/en/stable/introduction.html)和[Imblearn package study（不平衡数据处理之过采样、下采样、综合采样）](https://blog.csdn.net/kizgel/article/details/78553009?locationNum=6&fps=1), 编辑:Weiyang,Time:2019.2.9,weixin:damo894127201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed Sparse Rows(CSR):压缩稀疏的行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse input:\n",
    "对于稀疏输入，数据会在灌进sampler前被转换成**压缩稀疏的行(CSR)表示**。为了避免不必要的内存拷贝，推荐将数据在程序入口用CSR表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "稀疏矩阵中存在许多0元素，按矩阵$A$的原始形式进行存储会占用很大的内存空间。CSR方法采取**按行压缩**的办法，将原始矩阵用三个数组进行表示:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "indices = np.array([0, 2, 2, 0, 1, 2])\n",
    "indptr = np.array([0, 2, 3, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. data数组:存储着矩阵$A$中所有的非零元素\n",
    "2. indices数组:data数组中的元素在矩阵$A$列索引\n",
    "3. indptr数组:用来推断矩阵$A$中每行非零元素的列索引以及其值\n",
    "4. csr_matrix((data,indices,indptr),shape=(m,n))是标准的CSR表示，对于第$i$行来说，它的非零元素的列索引存储在indices[indptr[i]:indptr[i+1]],相应的值存储在data[indptr[i]:indptr[i+1]]。如果shape参数未给定，重构的矩阵维度将会自动推断"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据上述信息重构矩阵，维度自动推断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 2],\n",
       "        [0, 0, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "matrix = sparse.csr_matrix((data,indices,indptr))\n",
    "matrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么会有针对不平衡数据的研究呢？当我们的样本数据中，正负样本的数据占比极其不均衡的时候，模型的效果就会偏向于多数类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 过采样(Over-sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素随机过采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对不平衡数据，最简单的方法是**生成少数类的样本**，实现它的最基本的方法便是从少数类的样本中进行随机采样来增加新的样本，**$RandomOverSampler$**函数就实现了此功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用sklearn.datasets.make_classification来生成一些分类的伪数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "\n",
    "X,Y = make_classification(n_samples=5000, # 生成的数据个数\n",
    "                          n_features=3, # 特征个数=n_informative+n_redundant+n_repeated\n",
    "                          n_informative=3,#具备独立信息的特征个数\n",
    "                          n_redundant=0,# 冗余特征的个数，冗余特征是informative特征的随机线性组合\n",
    "                          n_repeated=0, # 重复特征的个数，它是随机提取n_informative和n_redundant特征\n",
    "                          n_classes=3, # 类别个数\n",
    "                          n_clusters_per_class=2,#每个类别有几个聚类中心\n",
    "                          weights=[0.01,0.05,0.94],# 每个类别占有的数据量比例\n",
    "                          flip_y=0.01,\n",
    "                          class_sep=1.0,# 乘以超立方体大小的因子。较大的值分散了簇/类，并使分类任务更容易。\n",
    "                          hypercube=True,\n",
    "                          shift=0.0,\n",
    "                          scale=1.0,\n",
    "                          shuffle=True,# 数据混洗\n",
    "                          random_state=0\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make_classification()返回值:\n",
    "1. X:数组shape为[n_samples，n_features]，它是生成的样本\n",
    "2. Y:数组shape为[n_samples]，它是每个样本的类成员的整数标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3) (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计各类别的样本数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 266, 2: 4665})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对少数类进行朴素随机过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "sampler = RandomOverSampler() # 采样器\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y) # 随机采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采样结果,各类别比例1:1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13995, 3) (13995,)\n"
     ]
    }
   ],
   "source": [
    "print(X_resampled.shape,Y_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4665, 1: 4665, 2: 4665})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从随机过采样到SOMOTE与ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相对于朴素随机过采样的方法, 还有两种比较流行的采样少数类的方法:\n",
    "1. Synthetic Minority Oversampling Technique (SMOTE)\n",
    "2. Adaptive Synthetic (ADASYN)\n",
    "\n",
    "SMOTE: 对于少数类样本a, 随机选择一个最近邻的样本b, 然后从a与b的连线上随机选取一个点c作为新的少数类样本\n",
    "ADASYN: 关注的是在那些基于K最近邻分类器被错误分类的原始样本附近生成新的少数类样本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE,ADASYN\n",
    "\n",
    "X_resampled_SMOTE,Y_resampled_SMOTE = SMOTE().fit_sample(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采样结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13995, 3) (13995,)\n"
     ]
    }
   ],
   "source": [
    "print(X_resampled_SMOTE.shape,Y_resampled_SMOTE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4665, 1: 4665, 2: 4665})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Y_resampled_SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13992, 3) (13992,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 4680, 1: 4647, 2: 4665})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE,ADASYN\n",
    "\n",
    "X_resampled_SMOTE,Y_resampled_SMOTE = ADASYN().fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled_SMOTE.shape,Y_resampled_SMOTE.shape)\n",
    "Counter(Y_resampled_SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE的变体：borderline-1,borderline-2,svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相对于基本的SMOTE算法关注的是所有的少数类样本, 这些情况可能会导致产生次优的决策函数, 因此SMOTE就产生了一些变体: 这些方法关注在最优化决策函数边界的一些少数类样本, 然后在最近邻类的相反方向生成样本.\n",
    "\n",
    "SMOTE函数中的kind参数控制了选择哪种变体:\n",
    "1. borderline1\n",
    "2. borderline2\n",
    "3. svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### borderline-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE,ADASYN\n",
    "\n",
    "X_resampled,Y_resampled = SMOTE(kind='borderline1').fit_sample(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采样结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13995, 3) (13995,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 4665, 1: 4665, 2: 4665})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### borderline-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13994, 3) (13994,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 4664, 1: 4665, 2: 4665})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE,ADASYN\n",
    "\n",
    "X_resampled,Y_resampled = SMOTE(kind='borderline2').fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13995, 3) (13995,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 4665, 1: 4665, 2: 4665})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE,ADASYN\n",
    "\n",
    "X_resampled,Y_resampled = SMOTE(kind='svm').fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE，ADASYN，borderline-1,borderline-2,svm比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SMOTE算法**与**ADASYN**都是基于同样的算法来合成新的少数类样本: 对于少数类样本a, 从它的最近邻中选择一个样本b, 然后在两点的连线上随机生成一个新的少数类样本, 不同的是对于少数类样本的选择.\n",
    "\n",
    "原始的SMOTE: kind='regular' , 随机选取少数类的样本.\n",
    "\n",
    "The borderline SMOTE: kind='borderline1' or kind='borderline2'\n",
    "\n",
    "此时, 少数类的样本分为三类: \n",
    "1. 噪音样本(noise), 该少数类的所有最近邻样本都来自于不同于样本a的其他类别\n",
    "2. 危险样本(in danger), 至少一半的最近邻样本来自于同一类(不同于a的类别)\n",
    "3. 安全样本(safe), 所有的最近邻样本都来自于同一个类\n",
    "\n",
    "这两种类型的SMOTE使用的是**危险样本**来生成新的样本数据:\n",
    "1. 对于 Borderline-1 SMOTE, 最近邻中的随机样本b与该少数类样本a来自于不同的类; \n",
    "2. 对于 Borderline-2 SMOTE , 随机样本b可以是属于任何一个类的样本;\n",
    "\n",
    "SVM SMOTE: kind='svm', 使用支持向量机分类器产生支持向量然后再生成新的少数类样本."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 欠采样(下采样Under-sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原型生成算法(prototype generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定数据集$S$, 原型生成算法将生成一个子集$S’$, 其中$|S’| < |S|$, 但是**子集并非来自于原始数据集**. 意思就是说: 原型生成方法将减少数据集的样本数量, 新样本是由原始数据集生成的, 而不是直接来源于原始数据集。\n",
    "\n",
    "**ClusterCentroids函数**实现了上述功能: 每一个类别的样本都会用K-Means算法的中心点来进行合成, 而不是随机从原始样本进行抽取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 69, 2: 69})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "sampler = ClusterCentroids()\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClusterCentroids函数提供了一种很高效的方法来减少样本的数量, 但需要注意的是, 该方法要求原始数据集最好能聚类成簇。 此外, 中心点的数量应该设置好, 这样下采样的簇能很好地代表原始数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原型选择算法(prototype selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与原型生成不同的是, 原型选择算法是直接从原始数据集中进行抽取. 抽取的方法大概可以分为两类: \n",
    "1. 可控的下采样技术(The controlled under-sampling techniques)\n",
    "2. 下采样清洗技术(the cleaning under-sampling techniques)\n",
    "\n",
    "**可控的下采样技术**可以由用户指定下采样抽取的子集中样本的数量; 下采样清洗技术则不接受这种用户的干预。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Controlled under-sampling techniques：可控的下采样技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 朴素的下采样技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomUnderSampler**函数是一种快速并十分简单的方式来平衡各个类别的数据: 随机选取数据的子集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 3) (207,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 69, 2: 69})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "sampler = RandomUnderSampler(random_state=0) # 默认重复采样\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过设置RandomUnderSampler中的replacement=True参数, 可以实现不重复抽样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 3) (207,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 69, 2: 69})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "sampler = RandomUnderSampler(random_state=0,replacement=True)\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看采样是否重复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(195, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.vstack({tuple(row) for row in X_resampled}).shape# set的列表推断,达到去重的目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "195 < 207 由此可见，replacement=True是不重复采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Near Miss方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NearMiss函数则添加了一些启发式(heuristic)的规则来选择样本, 通过设定version参数来实现三种启发式的规则。下面通过一个例子来说明这三个启发式的选择样本的规则, 首先我们假设正样本是需要下采样的(多数类样本), 负样本是少数类的样本.\n",
    "\n",
    "1. NearMiss-1: 选择离N个最近邻的负样本的平均距离最小的正样本\n",
    "2. NearMiss-2: 选择离N个最远的负样本的平均距离最小的正样本\n",
    "3. NearMiss-3: 是一个两段式的算法。首先, 对于每一个负样本, 保留它们的M个近邻样本; 接着, 那些到N个近邻样本平均距离最大的正样本将被选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 3) (207,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 69, 2: 69})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "sampler = NearMiss(random_state=0,version=1) # version=1,2,3\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning under-sampling techniques：下采样清洗技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tomek’s links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TomekLinks : 样本x与样本y来自于不同的类别, 满足以下条件, 它们之间被称之为TomekLinks:\n",
    "![tomek_links](./image/tomek_links.png)\n",
    "\n",
    "1. 不存在另外一个样本z, 使得d(x,z) < d(x,y) 或者 d(y,z) < d(x,y)成立\n",
    "2. 其中d(.)表示两个样本之间的距离, 也就是说两个样本之间互为最近邻关系\n",
    "3. 这个时候, 样本x或样本y很有可能是噪声数据, 或者两个样本在边界的位置附近\n",
    "\n",
    "TomekLinks函数中的sampling_strategy参数控制Tomek’s links中的哪些样本被剔除:\n",
    "1. 当sampling_strategy为str时，指定重采样的类别。注意被采样的类别数据数量要不一致，可选的参数有:\n",
    "    1. 默认的sampling_strategy='auto' 移除多数类的样本 \n",
    "    2. 当sampling_strategy='all'时, 多数类和少数类样本均被移除\n",
    "    3. 当sampling_strategy='majority'时,只对大多数类采样\n",
    "    4. 当sampling_strategy='not minority'时,对其他所有类别重采样，除了数量最少的类别\n",
    "    5. 当sampling_strategy='not majority'时，对其他所有类别重采样，除了数量最多的类别\n",
    "2. 当sampling_strategy为list时，list中包含被采样的类别\n",
    "\n",
    "![tomek_links_2](./image/tomek_links_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4865, 3) (4865,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 206, 2: 4590})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "sampler = TomekLinks(sampling_strategy='auto')\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EditedNearestNeighbours :Edited data set using nearest neighbours(最近邻规则或ENN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EditedNearestNeighbours**这种方法应用**最近邻算法来编辑(edit)数据集**, 找出那些**与邻居不太友好的样本**然后移除。对于每一个要进行下采样的样本, 那些不满足一些准则的样本将会被移除:他们的绝大多(kind_sel='mode')或者全部(kind_sel='all')的近邻样本都属于同一个类, 这些样本会被保留在数据集中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EditedNearestNeighbours(sampling_strategy,kind_sel)**算法\n",
    "1. sampling_strategy同上\n",
    "2. kind_sel='all'或者'mode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4509, 3) (4509,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 108, 2: 4332})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "sampler = EditedNearestNeighbours(random_state=0,kind_sel='all')\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RepeatedEditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RepeatedEditedNearestNeighbours(sampling_strategy,kind_sel,max_iter)**算法\n",
    "1. 算法目的是重复EditedNearestNeighbours算法多次\n",
    "2. 参数sampling_strategy,kind_sel含义同上\n",
    "3. max_iter，单轮最大迭代次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4450, 3) (4450,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 96, 2: 4285})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
    "\n",
    "sampler = RepeatedEditedNearestNeighbours(random_state=0,max_iter=100)\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AllKNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AllKNN()**算法\n",
    "1. 与RepeatedEditedNearestNeighbours算法不同的是, ALLKNN算法在进行每次迭代的时候, 最近邻的数量都在增加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4609, 3) (4609,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 113, 2: 4427})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import AllKNN\n",
    "\n",
    "sampler = AllKNN(random_state=0)\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CondensedNearestNeighbour: Condensed nearest neighbors and derived algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CondensedNearestNeighbour 使用1近邻的方法来进行迭代, 来判断一个样本是应该保留还是剔除, 具体的实现步骤如下:\n",
    "1. 集合C: 所有的少数类样本\n",
    "2. 选择一个多数类样本(需要下采样)加入集合C, 其他的这类样本放入集合S\n",
    "3. 使用集合S训练一个1-NN的分类器, 对集合S中的样本进行分类(能够被正确分类的样本是无用的，因为有其它样本已经包含了该样本的信息)\n",
    "4. 将集合S中错分的样本加入集合C\n",
    "5. 重复上述过程, 直到没有样本再加入到集合C\n",
    "6. 集合C便是保留的新样本集合，其它样本删除即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(367, 3) (367,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 54, 2: 244})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "\n",
    "sampler = CondensedNearestNeighbour(random_state=0)\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显然, CondensedNearestNeighbour方法**对噪音数据是很敏感的**, 也容易加入噪音数据到集合C中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneSidedSelection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneSidedSelection 函数使用 TomekLinks 方法来剔除噪声数据(多数类样本)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4463, 3) (4463,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 168, 2: 4226})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "\n",
    "sampler = OneSidedSelection(random_state=0)\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NeighbourhoodCleaningRule ：邻域清理规则，NCL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeighbourhoodCleaningRule 算法主要关注如何清洗数据而不是筛选他们。\n",
    "因此, 该算法将使用EditedNearestNeighbours和 3-NN分类器结果拒绝的样本之间的并集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要思想:\n",
    "针对训练样本集中的每个样本找出其三个最近邻样本，若该样本是多数类样本且其三个最近邻中有两个以上是少数类样本，则删除它；反之当该样本是少数类并且其三个最近邻中有两个以上是多数类样本，则去除近邻中的多数类样本。\n",
    "\n",
    "缺陷:\n",
    "未能考虑到在少数类样本中存在的噪声样本而且第二种方法删除的多数类样本大多属于边界样本，删除这些样本，对后续分类器的分类产生很大的不良影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4820, 3) (4820,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 157, 2: 4594})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "\n",
    "sampler = NeighbourhoodCleaningRule(random_state=0)\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### InstanceHardnessThreshold: Instance hardness threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InstanceHardnessThreshold是在数据上运用一种**分类器**, 然后将概率低于阈值的样本剔除掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 3) (207,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 69, 2: 69})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "\n",
    "sampler = InstanceHardnessThreshold(random_state=0,estimator=LogisticRegression())\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 过采样和欠采样的结合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在之前的SMOTE方法中, 当由边界的样本与其他样本进行过采样线性插值时, 很容易生成一些噪音数据. 因此, 在过采样之后需要对样本进行清洗. 这样, 第三节中涉及到的**TomekLink** 与 **EditedNearestNeighbours**方法就能实现上述的要求. 所以就有了两种结合过采样与下采样的方法: (i) SMOTETomek and (ii) SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE+ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11824, 3) (11824,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 4190, 1: 4257, 2: 3377})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "sampler = SMOTEENN(random_state=0)\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE+TomekLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13671, 3) (13671,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 4598, 1: 4567, 2: 4506})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "sampler = SMOTETomek(random_state=0)\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble:数据集的集成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个不均衡的数据集能够通过多个均衡的子集来实现均衡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EasyEnsemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个不均衡的数据集能够通过多个均衡的子集来实现均衡, imblearn.ensemble模块能实现上述功能。\n",
    "\n",
    "EasyEnsemble 通过对原始的数据集进行随机下采样实现对数据集进行集成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 207, 3) (10, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class EasyEnsemble is deprecated; EasyEnsemble is deprecated in 0.4 and will be removed in 0.6. Use EasyEnsembleClassifier instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 69, 2: 69})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import EasyEnsemble\n",
    "\n",
    "sampler = EasyEnsemble(random_state=0,n_subsets=10)\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled[0]) # 取一个子集看看各类的比例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EasyEnsemble 有两个很重要的参数: \n",
    "1. n_subsets 控制的是子集的个数  \n",
    "2. replacement 决定是有放回还是无放回的随机采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BalanceCascade:级联平衡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BalanceCascade(级联平衡)的方法通过使用**分类器(estimator参数)**来确保那些**被错分类的样本**在下一次进行子集选取的时候也能被采样到. 同样, n_max_subset 参数控制子集的个数, 以及可以通过设置bootstrap=True来使用bootstraping(自助法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 207, 3) (3, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class BalanceCascade is deprecated; BalanceCascade is deprecated in 0.4 and will be removed in 0.6.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 69, 1: 69, 2: 69})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import BalanceCascade\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sampler = BalanceCascade(random_state=0,\n",
    "                         estimator=LogisticRegression(random_state=0),\n",
    "                         n_max_subset=3\n",
    "                        )\n",
    "X_resampled,Y_resampled = sampler.fit_sample(X,Y)\n",
    "\n",
    "print(X_resampled.shape,Y_resampled.shape)\n",
    "Counter(Y_resampled[0]) #取一个子集看看各类的比例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining ensemble of samplers and estimators：Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在集成分类器中, 装袋方法(Bagging)在**不同的随机选取的数据集**上建立了多个估计量. 在scikit-learn中这个分类器叫做**BaggingClassifier**. 然而, 该分类器并不允许对每个数据集进行均衡. 因此, 在对不均衡样本进行训练的时候, 分类器其实是有偏的, 偏向于多数类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在sklearn上使用**BaggingClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   6,    4,   12],\n",
       "       [   1,   42,   31],\n",
       "       [   3,   11, 1140]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,random_state=0)\n",
    "model = BaggingClassifier(base_estimator=DecisionTreeClassifier(),random_state=0)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "confusion_matrix(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BalancedBaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BalancedBaggingClassifier 允许在训练每个基学习器之前对每个子集进行重抽样. 简而言之, 该方法结合了EasyEnsemble 采样器与分类器(如BaggingClassifier)的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8,   7,   7],\n",
       "       [ 13,  54,   7],\n",
       "       [164, 121, 869]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "model = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                  ratio='auto',\n",
    "                                  replacement=False,\n",
    "                                  random_state=0\n",
    "                                 )\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "confusion_matrix(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据载入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**imblearn.datasets** 包与**sklearn.datasets** 包形成了很好的互补. 该包主要有以下两个功能: \n",
    "1. 提供一系列的不平衡数据集来实现测试\n",
    "2. 提供一种工具将原始的平衡数据转换为不平衡数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不平衡数据集:fetch_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetch_datasets 允许获取27个不均衡且二值化的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "from collections import Counter\n",
    "from imblearn.datasets import fetch_datasets\n",
    "\n",
    "ecoli = fetch_datasets()['ecoli']\n",
    "ecoli.data.shape\n",
    "Counter(ecoli.target)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成不平衡数据:make_imblance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make_imbalance 方法可以使得原始的数据集变为不平衡的数据集, 主要是通过ratio参数进行控制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/imblearn/datasets/_imbalance.py:105: UserWarning: 'ratio' has been deprecated in 0.4 and will be removed in 0.6. Use 'sampling_strategy' instead.\n",
      "  warnings.warn(\"'ratio' has been deprecated in 0.4 and will be \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 20), (1, 30), (2, 40)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from imblearn.datasets import make_imbalance\n",
    "\n",
    "iris = load_iris()\n",
    "ratio = {0: 20, 1: 30, 2: 40} # 各类别导入的数据量\n",
    "X_imb, y_imb = make_imbalance(iris.data, iris.target, ratio=ratio)\n",
    "\n",
    "sorted(Counter(y_imb).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/imblearn/datasets/_imbalance.py:105: UserWarning: 'ratio' has been deprecated in 0.4 and will be removed in 0.6. Use 'sampling_strategy' instead.\n",
      "  warnings.warn(\"'ratio' has been deprecated in 0.4 and will be \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 10), (1, 50), (2, 50)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#当类别不指定时, 所有的数据集均导入\n",
    "ratio = {0: 10} # 类别0导入10条，其他各类全都导入\n",
    "X_imb, y_imb = make_imbalance(iris.data, iris.target, ratio=ratio)\n",
    "\n",
    "sorted(Counter(y_imb).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/imblearn/datasets/_imbalance.py:105: UserWarning: 'ratio' has been deprecated in 0.4 and will be removed in 0.6. Use 'sampling_strategy' instead.\n",
      "  warnings.warn(\"'ratio' has been deprecated in 0.4 and will be \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 25), (1, 35), (2, 47)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#同样亦可以传入自定义的比例函数\n",
    "def ratio_multiplier(y):\n",
    "    multiplier = {0: 0.5, 1: 0.7, 2: 0.95} # 各类别导入各自数据量的比例\n",
    "    target_stats = Counter(y)\n",
    "    for key, value in target_stats.items():\n",
    "        target_stats[key] = int(value * multiplier[key])\n",
    "    return target_stats\n",
    "X_imb, y_imb = make_imbalance(iris.data, iris.target,\n",
    "                              ratio=ratio_multiplier)\n",
    "\n",
    "sorted(Counter(y_imb).items())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
