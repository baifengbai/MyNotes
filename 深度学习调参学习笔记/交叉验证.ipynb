{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文学习于[scikit-learn:Cross-validation: evaluating estimator performance](https://scikit-learn.org/stable/modules/cross_validation.html)和[交叉验证 Cross-validation](https://www.cnblogs.com/sddai/p/5696834.html),编辑:Weiyang,Time:2019.2.13,weixin:damo894127201 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练集、验证集和测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在模式识别(pattern recognition)与机器学习(machine learning)的相关研究中，经常会将**数据集(Dataset)**分为**训练集(training set)**和**测试集(testing set)**两个子集。**训练集**用于建立模型model，**测试集**用来评估该模型对未知样本进行预测的精确度，即**模型的泛化能力(generalization ability)**。\n",
    "\n",
    "训练模型需要对模型进行调参，这时，进一步将原来的训练集分为**训练集**和**验证集**，以便于进行交叉验证以寻找模型最佳的参数配置。此时，**训练集**仍然用于训练模型，而**验证集**用于寻找最佳的参数配置，**测试集**用于评估模型的**泛化能力**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何将数据集划分为训练集和测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必须遵循以下要点:\n",
    "1. 只有训练集才可以用在模型的训练过程中，测试集则必须在模型训练完成之后被用来评估模型优劣\n",
    "2. 训练集中样本数量必须够多，一般至少大于总样本数的50%\n",
    "3. 两组子集必须从完整数据集中**均匀采样**\n",
    "\n",
    "**均匀采样**的目的是希望减少训练集/测试集与完整集合之间的**偏差(bias)**。一般的做法是**随机采样**，当样本数量足够多时，便可达到**均匀采样**的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分训练集和测试集的函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.model_selection.train_test_split函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_test_split()**函数直接返回划分完毕的训练集和测试集**本身**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3500, 5), (1500, 5))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 构造数据集\n",
    "X,Y = make_classification(n_samples=5000,\n",
    "                          n_features=5,\n",
    "                          n_informative=3,\n",
    "                          n_redundant=1,\n",
    "                          n_repeated=1,\n",
    "                          n_classes=2,\n",
    "                         )\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,shuffle=True)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.model_selection.ShuffleSplit函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ShuffleSplit（）**函数返回划分完毕的训练集和测试集在数据集中的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 403 3578 3729 ... 3149 3603 2293] TEST: [1588 4667 1031 ... 2174 2956 2727]\n",
      "TRAIN: 3500 TEST: 1500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "rs = ShuffleSplit(n_splits=1,test_size=0.3)\n",
    "# 获取划分后训练集和测试集在原数据集中的索引\n",
    "for train_index,test_index in rs.split(X):\n",
    "    print(\"TRAIN:\",train_index,\"TEST:\",test_index)\n",
    "    print(\"TRAIN:\",len(train_index),\"TEST:\",len(test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. n_splits:表明划分成几个 '训练集和测试集对'\n",
    "2. test_size:表明每个 '训练集和测试集对' 中测试集占总数据量的比例\n",
    "3. 该函数一般用于交叉验证划分训练集和验证集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉验证：评估不同模型的性能和调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 思想阐述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**交叉验证(Cross Validation，CV)**是用来**验证模型性能**一种统计分析方法，**基本思想**是将原始训练集（training set）进行分组，一部分继续作为**训练集(training set)**,另一部分作为**验证集(validation set)**,首先用**训练集**对模型进行训练，再利用**验证集**来测试训练得到的模型（model）性能，将每次得到的**模型性能指标取平均**作为评价模型性能的指标。\n",
    "\n",
    "1. 用交叉验证来评估不同模型的性能\n",
    "    1. 如果对不同的模型，进行交叉验证，便可以根据模型的平均性能来评估模型的优劣\n",
    "\n",
    "2. 用交叉验证来调参\n",
    "    1. 如果固定模型，对不同的参数组合，进行交叉验证，便可以根据模型的平均性能来评估参数的优劣。同一K折交叉验证中，这K次迭代的是同一组参数\n",
    "\n",
    "常见的交叉验证方法如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-Out Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法阐述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将原始训练集随机分为两组，一组作为训练集，一组作为验证集，利用训练集训练模型，然后在验证集上测试模型，比如准确率。\n",
    "\n",
    "此种方法的好处是处理简单，只需随机把原始数据分为两组即可，其实严格意义来说Hold-Out Method并不能算是CV，因为这种方法没有达到交叉的思想，由于是随机的将原始数据分组，所以最后验证集分类准确率的高低与原始数据的分组有很大的关系，所以这种方法得到的结果其实并不具有说服性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.train_test_split函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只需将原来的训练集进一步 调用train_test_split()函数 即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.ShuffleSplit函数：返回索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置参数 n_splits=1 即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold :K-CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法阐述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K折交叉验证**:\n",
    "1. 将原始数据分成K组（一般是均分采样）\n",
    "2. 将每个子集数据分别做一次验证集\n",
    "3. 其余的K-1组子集数据作为训练集\n",
    "4. 分别训练得到K个模型\n",
    "5. 用这K个模型在验证集上的性能指标(比如分类准确率)的**平均数**作为此 K-CV下分类器的性能指标\n",
    "\n",
    "![k_fold](./image/k_fold.png)\n",
    "\n",
    "K一般大于等于2，实际操作时一般从3开始取，只有在原始数据集合数据量小的时候才会尝试取 2 。K-CV可以有效的避免过拟合学习以及欠拟合学习状态的发生，最后得到的结果也比较具有说服性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn实现:sklearn.model_selection.KFold函数：返回索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意返回的是索引，如果要获取对应的元素，可以将原数据集转化为numpy数组，然后使用numpy数组索引的特殊功能:numpy.arrays[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 4500 VALIDATE: 500\n",
      "TRAIN: 4500 VALIDATE: 500\n",
      "TRAIN: 4500 VALIDATE: 500\n",
      "TRAIN: 4500 VALIDATE: 500\n",
      "TRAIN: 4500 VALIDATE: 500\n",
      "TRAIN: 4500 VALIDATE: 500\n",
      "TRAIN: 4500 VALIDATE: 500\n",
      "TRAIN: 4500 VALIDATE: 500\n",
      "TRAIN: 4500 VALIDATE: 500\n",
      "TRAIN: 4500 VALIDATE: 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "for train_index,validate_index in kf.split(X):\n",
    "    print(\"TRAIN:\",len(train_index),\"VALIDATE:\",len(validate_index)) # 查看训练集和测试集的大小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数n_splits=k，表示K折交叉验证，而训练集和验证集的大小比例，则由k自动推断"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-One-Out :留一法，LOO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法阐述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果设原始数据有N个样本，那么LOO-CV就是N-CV，即每个样本单独作为验证集，其余的N-1个样本作为训练集，所以LOO-CV会得到N个模型，用这N个模型最终的验证集的分类准确率的平均数作为此下LOO-CV分类器的性能指标。\n",
    "\n",
    "相比于前面的K-CV，LOO-CV有两个明显的优点：\n",
    "1. 每一回合中几乎所有的样本皆用于训练模型，因此最接近原始样本的分布，这样评估所得的结果比较可靠\n",
    "2. 实验过程中没有随机因素会影响实验数据，确保实验过程是可以被复制的\n",
    "但LOO-CV的缺点则是**计算成本高**，因为需要建立的模型数量与原始数据样本数量相同，当原始数据样本数量相当多时，LOO-CV便很慢，除非每次训练分类器得到模型的速度很快，或是可以用并行化计算减少计算所需的时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn实现:sklearn.model_selection.LeaveOneOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意返回的是索引，如果要获取对应的元素，可以将原数据集转化为numpy数组，然后使用numpy数组索引的特殊功能:numpy.arrays[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1 2 3] VALIDATE: [0]\n",
      "TRAIN: [0 2 3] VALIDATE: [1]\n",
      "TRAIN: [0 1 3] VALIDATE: [2]\n",
      "TRAIN: [0 1 2] VALIDATE: [3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "x = ['a','b','c','d']\n",
    "loo = LeaveOneOut()\n",
    "for train_index,validate_index in loo.split(x):\n",
    "    print(\"TRAIN:\",train_index,\"VALIDATE:\",validate_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave P out ：LPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法阐述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与**Leave-One-Out**相似，只不过每次是留下**P**个样本作为**验证集**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn实现:sklearn.model_selection.LeavePOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意返回的是索引，如果要获取对应的元素，可以将原数据集转化为numpy数组，然后使用numpy数组索引的特殊功能:numpy.arrays[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [2 3 4 5] VALIDATE: [0 1]\n",
      "TRAIN: [1 3 4 5] VALIDATE: [0 2]\n",
      "TRAIN: [1 2 4 5] VALIDATE: [0 3]\n",
      "TRAIN: [1 2 3 5] VALIDATE: [0 4]\n",
      "TRAIN: [1 2 3 4] VALIDATE: [0 5]\n",
      "TRAIN: [0 3 4 5] VALIDATE: [1 2]\n",
      "TRAIN: [0 2 4 5] VALIDATE: [1 3]\n",
      "TRAIN: [0 2 3 5] VALIDATE: [1 4]\n",
      "TRAIN: [0 2 3 4] VALIDATE: [1 5]\n",
      "TRAIN: [0 1 4 5] VALIDATE: [2 3]\n",
      "TRAIN: [0 1 3 5] VALIDATE: [2 4]\n",
      "TRAIN: [0 1 3 4] VALIDATE: [2 5]\n",
      "TRAIN: [0 1 2 5] VALIDATE: [3 4]\n",
      "TRAIN: [0 1 2 4] VALIDATE: [3 5]\n",
      "TRAIN: [0 1 2 3] VALIDATE: [4 5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "\n",
    "x = ['a','b','c','d','e','f']\n",
    "lpo = LeavePOut(p=2)\n",
    "for train_index,validate_index in lpo.split(x):\n",
    "    print(\"TRAIN:\",train_index,\"VALIDATE:\",validate_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉验证的替代方案: sklearn.model_selection.ShuffleSplit函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ShuffleSplit()**每次划分数据集时都要混洗数据集，然后再将数据集划分为**训练集**和**测试集**，当然这里的**测试集**也可以称为**验证集**。\n",
    "1. ShuffleSplit是有放回抽样,抽样生成训练集和测试集\n",
    "2. 可以指定抽样次数，即将原数据集划分成多个'训练集和测试集对'，而每个'训练集和测试集对'合在一起便是原数据集\n",
    "3. 可以指定训练集和测试集的占原数据集的比例\n",
    "\n",
    "![shuffle_split](./image/shuffle_split.png)\n",
    "因此ShuffleSplit()可以更精细地控制迭代次数(抽样次数)和每轮迭代中训练集和测试集的比例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意返回的是索引，如果要获取对应的元素，可以将原数据集转化为numpy数组，然后使用numpy数组索引的特殊功能:numpy.arrays[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 3 5 1] VALIDATE: [2 4]\n",
      "TRAIN: [0 4 5 2] VALIDATE: [1 3]\n",
      "TRAIN: [1 2 0 4] VALIDATE: [5 3]\n",
      "TRAIN: [4 5 2 1] VALIDATE: [3 0]\n",
      "TRAIN: [0 5 1 2] VALIDATE: [4 3]\n",
      "TRAIN: [3 1 5 0] VALIDATE: [4 2]\n",
      "TRAIN: [2 3 0 4] VALIDATE: [1 5]\n",
      "TRAIN: [4 3 2 5] VALIDATE: [0 1]\n",
      "TRAIN: [1 0 4 5] VALIDATE: [3 2]\n",
      "TRAIN: [1 2 5 3] VALIDATE: [4 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "x = ['a','b','c','d','e','f']\n",
    "rs = ShuffleSplit(n_splits=10,test_size=0.3)\n",
    "for train_index,validate_index in rs.split(x):\n",
    "    print(\"TRAIN:\",train_index,\"VALIDATE:\",validate_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
